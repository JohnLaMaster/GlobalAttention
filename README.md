# nn.GlobalAttention
Pytorch module for implementing global attention as described in my new paper
